{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn,functional\nfrom torch.autograd import Variable\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"../input\"))\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8d3a878e938729abe76d9326d799b14ef0c003e"
      },
      "cell_type": "code",
      "source": "#Loading the data\ntrain = pd.read_csv(\"../input/train.csv\")\nX = train.loc[:,train.columns != \"label\"].values/255   #Normalizing the values\nY = train.label.values\n\nfeatures_train, features_test, targets_train, targets_test = train_test_split(X,Y,test_size=0.2,\n                                                                              random_state=42)\nX_train = torch.from_numpy(features_train)\nX_test = torch.from_numpy(features_test)\n\nY_train = torch.from_numpy(targets_train).type(torch.LongTensor) \nY_test = torch.from_numpy(targets_test).type(torch.LongTensor)\n\ntrain = torch.utils.data.TensorDataset(X_train,Y_train)\ntest = torch.utils.data.TensorDataset(X_test,Y_test)\n\n\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = 100, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = 100, shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81b549484a9fe5f1f6582d52db4dc5e1febf843a"
      },
      "cell_type": "code",
      "source": "class CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n        self.cnn_1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        \n        self.cnn_2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n        \n    def forward(self,x):\n        \n        out = self.cnn_1(x)\n        out = self.relu1(out)\n        out = self.maxpool1(out)\n        \n        out = self.cnn_2(out)\n        out = self.relu2(out)\n        out = self.maxpool2(out)\n        \n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        \n        return out\n        \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "afee23b7c9c3adc2aa350012d592217f22f1c16a"
      },
      "cell_type": "code",
      "source": "model = CNN()\nmodel = model.double()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(),lr=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adb7e2d0e11332589c3dd8ec031fdc173736b132"
      },
      "cell_type": "code",
      "source": "epochs = 15\ntrain_losses, test_losses = [] ,[]\nfor epoch in range(epochs):\n    running_loss = 0\n    for images,labels in train_loader:\n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        optimizer.zero_grad()\n        \n        output = model(train)\n        loss = criterion(output,labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        \n        with torch.no_grad(): #Turning off gradients to speed up\n            model.eval()\n            for images,labels in test_loader:\n                \n                test = Variable(images.view(100,1,28,28))\n                labels = Variable(labels)\n                \n                log_ps = model(test)\n                test_loss += criterion(log_ps,labels)\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim = 1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        model.train()        \n        train_losses.append(running_loss/len(train_loader))\n        test_losses.append(test_loss/len(test_loader))\n\n        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4030eff63670a6c45cb699bc90ae0651448ac54e"
      },
      "cell_type": "code",
      "source": "plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b21fef6db22f650bd374f0c2a7978ef09d457d3"
      },
      "cell_type": "code",
      "source": "test_images = pd.read_csv(\"../input/test.csv\")\ntest_image = test_images.loc[:,test_images.columns != \"label\"].values/255\ntest_dataset = torch.from_numpy(test_image)\n#test_dataset_1 = torch.utils.data.TensorDataset(test_dataset)\nnew_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "d46e513443a8a26c0f97e8abbd3cd8c37579fe47"
      },
      "cell_type": "code",
      "source": "with torch.no_grad():\n    model.eval()\n    for images in new_test_loader:\n        test = Variable(images.view(100,1,28,28))\n        output = model(test)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim = 1)\n       ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac0385e396a287d1604ad6a420258b7f583094bb"
      },
      "cell_type": "code",
      "source": "predlabel = top_class.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23264c2dfe626c0a6d23bc79c5e3e7db483e407d"
      },
      "cell_type": "code",
      "source": "predlabel = pd.DataFrame(predlabel)\npredlabel.index = np.arange(100) + 1\nid = np.arange(100) + 1\nid = pd.DataFrame(id)\nid.index = id.index + 1\n\npredlabel = pd.concat([id,predlabel], axis=1)\npredlabel.columns = [\"ImageId\", \"Label\"]\n\npredlabel.to_csv('predict.csv', index= False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1326cb0c978337a193e0c05e6fc4d81cd6f571a0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}